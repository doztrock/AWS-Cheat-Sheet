# 🔄 AWS Data Pipeline

---

## 📌 Description  
**AWS Data Pipeline** is a **web service** that enables you to **automate data movement and transformation** between different AWS compute and storage services, as well as on-premises sources.

---

## 🚀 Key Features  
- 🛠️ Automates data workflows (move, transform, process)  
- ⏱️ Schedule jobs at specific intervals  
- 🔁 Built-in retry and failure handling  
- 📦 Integrates with S3, RDS, Redshift, DynamoDB, EMR  
- 📊 Monitors pipeline execution status and sends alerts  

---

## 🛠️ Use Cases  
- ETL (Extract, Transform, Load) pipelines  
- Move data between on-premises and AWS  
- Schedule batch processing with EMR  
- Backup & archive workflows  
- Data transformation for reporting or analytics  

---

## 🔁 Comparison with Similar Services  

| Service                  | Difference from AWS Data Pipeline |
|--------------------------|-----------------------------------|
| **AWS Glue**             | Serverless ETL with built-in Data Catalog and Apache Spark engine. More modern, preferred for most ETL use cases. |
| **Amazon MWAA (Airflow)**| Managed Apache Airflow; more flexible for complex DAG-based workflows and cross-service orchestration. |
| **AWS Step Functions**   | Orchestrates workflows visually and integrates with a wide range of AWS services, ideal for microservices and serverless. |

---

## 💰 Pricing  
- 💵 Pay per pipeline activity and execution duration  
- 🆓 Free tier includes 5 low-frequency activities and 3 preconditions/month  

---

## 🧠 Exam Keywords  
- "Data orchestration service"  
- "ETL workflows"  
- "Move/transform data on schedule"  
- "Integrates with S3, EMR, RDS, Redshift"  
- "Fault-tolerant & retry mechanisms"
